"""
–ü–∞—Ä—Å–µ—Ä –ª–æ–¥–æ–∫ —Å boataround.com
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –¥–ª—è Django
"""
import json
import logging
import re
import os
from pathlib import Path
from typing import Optional
from bs4 import BeautifulSoup
import requests
import mimetypes

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º BoataroundAPI –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è equipment –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö
try:
    from boats.boataround_api import BoataroundAPI
except ImportError:
    BoataroundAPI = None

# Optional boto3 for S3 uploads
try:
    import boto3
    from botocore.exceptions import BotoCoreError, ClientError
except Exception:
    boto3 = None
    BotoCoreError = Exception
    ClientError = Exception

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# –ö–û–ù–°–¢–ê–ù–¢–´
# =============================================================================

BASE_URL = 'https://www.boataround.com/ru/yachta'
IMAGE_HOST = 'imageresizer.yachtsbt.com'
CDN_URL = 'https://cdn2.prvms.ru'
MEDIA_ROOT = '/app/media/boats'  # Docker path

BOAT_ID_PATTERN = re.compile(r'/boats/([a-f0-9]{24})/')
SLUG_FROM_URL_PATTERN = re.compile(r'/(?:boat|yachta)/([^/?#]+)')


def add_currency_param(url: str, currency: str = 'EUR') -> str:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –≤–∞–ª—é—Ç—ã –∫ URL.
    
    –ü—Ä–∏–º–µ—Ä—ã:
        https://www.boataround.com/ru/yachta/bavaria-cruiser-46
        -> https://www.boataround.com/ru/yachta/bavaria-cruiser-46?currency=EUR
        
        https://www.boataround.com/ru/yachta/bavaria-cruiser-46?checkIn=2025-05-01
        -> https://www.boataround.com/ru/yachta/bavaria-cruiser-46?checkIn=2025-05-01&currency=EUR
    """
    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
    
    parsed = urlparse(url)
    query_params = parse_qs(parsed.query, keep_blank_values=True)
    
    # –£–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–∫–∏ –∏–∑ parse_qs –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∞–ª—é—Ç—É
    flat_params = {k: v[0] if isinstance(v, list) else v for k, v in query_params.items()}
    flat_params['currency'] = currency
    
    # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ URL
    new_query = urlencode(flat_params)
    new_parsed = parsed._replace(query=new_query)
    result_url = urlunparse(new_parsed)
    
    logger.info(f"[URL] –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä currency={currency}: {result_url}")
    return result_url


# =============================================================================
# –°–û–•–†–ê–ù–ï–ù–ò–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô
# =============================================================================

def download_and_save_image(image_path: str) -> Optional[str]:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å imageresizer.yachtsbt.com –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç CDN URL –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —à–∞–±–ª–æ–Ω–∞—Ö.
    
    Args:
        image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, –Ω–∞–ø—Ä–∏–º–µ—Ä 'boats/62b96d157a9323583a5a4880/650d96fa43b7cac28800ead4.jpg'
    
    Returns:
        str: CDN URL –≤—Ä–æ–¥–µ 'https://cdn2.prvms.ru/yachts/{boat_id}/{filename}' –∏–ª–∏ None
    """
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º boat_id –∏ –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ –ø—É—Ç–∏
        # –ü—Ä–∏–º–µ—Ä: 'boats/62b96d157a9323583a5a4880/650d96fa43b7cac28800ead4.jpg'
        # -> boat_id='62b96d157a9323583a5a4880', filename='650d96fa43b7cac28800ead4.jpg'
        parts = image_path.strip('/').split('/')
        boat_id = None
        filename = None
        if len(parts) >= 2:
            # –ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç - –∏–º—è —Ñ–∞–π–ª–∞
            filename = parts[-1]
            # –≠–ª–µ–º–µ–Ω—Ç –ø–µ—Ä–µ–¥ –Ω–∏–º (–∏–ª–∏ –ø–µ—Ä–µ–¥ 'boats') - boat_id (24-—Å–∏–º–≤–æ–ª MongoDB ObjectId)
            for i, part in enumerate(parts):
                if len(part) == 24 and all(c in '0123456789abcdef' for c in part.lower()):
                    boat_id = part
                    break
        
        if not boat_id or not filename:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å boat_id –∏–ª–∏ filename –∏–∑ –ø—É—Ç–∏ {image_path}")
            return None
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        source_url = f"https://{IMAGE_HOST}/{image_path}?method=fit&width=1920&height=1080&format=jpeg"
        
        # –°–æ–∑–¥–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å
        local_path = Path(MEDIA_ROOT) / image_path
        local_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ‚≠ê –ì–õ–ê–í–ù–û–ï: CDN URL
        cdn_url = f"https://cdn2.prvms.ru/yachts/{boat_id}/{filename}"
        s3_key = f"{boat_id}/{filename}"
        
        # ‚≠ê –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –≤ S3, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º CDN URL (—ç–∫–æ–Ω–æ–º–∏–º —Ç—Ä–∞—Ñ–∏–∫)
        if check_s3_exists(s3_key):
            logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ –≤ S3: {s3_key} - –∏—Å–ø–æ–ª—å–∑—É–µ–º CDN URL")
            return cdn_url
        
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º CDN URL
        if local_path.exists():
            logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ: {image_path}")
            return cdn_url
        
        # –°–∫–∞—á–∏–≤–∞–µ–º
        logger.info(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {source_url}")
        response = requests.get(source_url, timeout=30, stream=True)
        response.raise_for_status()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        with open(local_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {local_path}")

        # ‚≠ê –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3 —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
        try:
            # skip_existing=True: –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º, –µ—Å–ª–∏ —É–∂–µ –≤ S3
            uploaded = upload_file_to_s3(local_path, s3_key, skip_existing=True)
            if uploaded:
                logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ S3: {s3_key}")
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤ S3: {e}")

        # ‚≠ê –í–æ–∑–≤—Ä–∞—â–∞–µ–º CDN URL
        return cdn_url
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
        return None


def get_cdn_url(image_path: str) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç URL –¥–ª—è CDN.
    
    Args:
        image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, –Ω–∞–ø—Ä–∏–º–µ—Ä '{boat_id}/{filename}.jpg'
    
    Returns:
        str: https://cdn2.prvms.ru/yachts/{boat_id}/{filename}.jpg
    """
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    clean_path = image_path.lstrip('/')
    if clean_path.startswith('boats/'):
        clean_path = clean_path[len('boats/'):]
    
    # –î–æ–±–∞–≤–ª—è–µ–º yachts/ –ø—Ä–µ—Ñ–∏–∫—Å (–∏–º—è –±–∞–∫–µ—Ç–∞)
    return f"{CDN_URL}/yachts/{clean_path}"


def check_s3_exists(s3_key: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –≤ S3.
    
    Args:
        s3_key: S3 object key (–Ω–∞–ø—Ä–∏–º–µ—Ä: '62b96d157a9323583a5a4880/650d96fa43b7cac28800ead4.jpg')
    
    Returns:
        bool: True –µ—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –≤ S3, False –∏–Ω–∞—á–µ
    """
    if boto3 is None:
        return False
    
    bucket = os.environ.get('S3_BUCKET_NAME')
    access_key = os.environ.get('AWS_ACCESS_KEY_ID')
    secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')
    endpoint = os.environ.get('S3_ENDPOINT_URL')
    region = os.environ.get('S3_REGION')
    
    if not bucket or not access_key or not secret_key:
        return False
    
    try:
        session = boto3.session.Session()
        client_kwargs = {
            'aws_access_key_id': access_key,
            'aws_secret_access_key': secret_key,
        }
        if region:
            client_kwargs['region_name'] = region
        if endpoint:
            s3 = session.client('s3', endpoint_url=endpoint, **client_kwargs)
        else:
            s3 = session.client('s3', **client_kwargs)
        
        s3_key = s3_key.lstrip('/')
        s3.head_object(Bucket=bucket, Key=s3_key)
        logger.debug(f"[S3 Check] –§–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {s3_key}")
        return True
    except Exception:
        # –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞
        return False


def upload_file_to_s3(local_path: Path, s3_key: str, skip_existing: bool = False) -> bool:
    """Upload a local file to S3-compatible storage.

    Reads configuration from environment variables:
      - S3_BUCKET_NAME
      - AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY
      - S3_ENDPOINT_URL (optional)
      - S3_REGION (optional)

    Args:
        local_path: Path to local file
        s3_key: S3 object key
        skip_existing: If True, skip upload if object already exists in S3

    Returns True if upload succeeded, False otherwise.
    """
    if boto3 is None:
        logger.debug("boto3 not installed; skipping S3 upload")
        return False

    bucket = os.environ.get('S3_BUCKET_NAME')
    access_key = os.environ.get('AWS_ACCESS_KEY_ID')
    secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')
    endpoint = os.environ.get('S3_ENDPOINT_URL')
    region = os.environ.get('S3_REGION')

    if not bucket or not access_key or not secret_key:
        logger.debug("S3 credentials or bucket not set; skipping S3 upload")
        return False

    try:
        session = boto3.session.Session()
        client_kwargs = {
            'aws_access_key_id': access_key,
            'aws_secret_access_key': secret_key,
        }
        if region:
            client_kwargs['region_name'] = region
        if endpoint:
            s3 = session.client('s3', endpoint_url=endpoint, **client_kwargs)
        else:
            s3 = session.client('s3', **client_kwargs)

        # Ensure key has no leading slash
        s3_key = s3_key.lstrip('/')

        logger.info(f"[S3 Upload] Uploading to bucket='{bucket}', key='{s3_key}'")

        # Check if object already exists (if skip_existing is True)
        if skip_existing:
            try:
                s3.head_object(Bucket=bucket, Key=s3_key)
                logger.info(f"[S3 Upload] Object already exists, skipping: {s3_key}")
                return True
            except Exception:
                # Object doesn't exist, proceed with upload
                pass

        # Determine content type
        content_type, _ = mimetypes.guess_type(str(local_path))
        extra_args = {}
        if content_type:
            extra_args['ContentType'] = content_type

        # Make public by default so CDN can fetch
        extra_args['ACL'] = 'public-read'

        # Upload
        if extra_args:
            s3.upload_file(str(local_path), bucket, s3_key, ExtraArgs=extra_args)
        else:
            s3.upload_file(str(local_path), bucket, s3_key)
        return True
    except (BotoCoreError, ClientError, Exception) as e:
        logger.error(f"S3 upload failed for {s3_key}: {e}")
        return False


# =============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –°–¢–†–ê–ù–ò–¶–´
# =============================================================================

def fetch_page(url: str) -> Optional[str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –æ–±—Ö–æ–¥–æ–º –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫."""
    import time
    import random
    
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ headers
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0',
        'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
    }
    
    # Retry –ª–æ–≥–∏–∫–∞
    max_retries = 3
    for attempt in range(max_retries):
        try:
            logger.info(f"[Requests] –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}: {url}")
            
            # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —á–µ–ª–æ–≤–µ–∫–∞
            if attempt > 0:
                delay = random.uniform(2, 5)
                logger.info(f"[Requests] –û–∂–∏–¥–∞–Ω–∏–µ {delay:.1f} —Å–µ–∫...")
                time.sleep(delay)
            
            # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –¥–ª—è cookies
            session = requests.Session()
            
            # –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è cookies
            response = session.get(
                url,
                headers=headers,
                timeout=30,
                allow_redirects=True,
                verify=True
            )
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
            if response.status_code == 200:
                logger.info(f"[Requests] –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(response.text)} –±–∞–π—Ç")
                return response.text
            elif response.status_code == 403:
                logger.warning(f"[Requests] 403 Forbidden, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}")
                continue
            elif response.status_code == 405:
                logger.warning(f"[Requests] 405 Method Not Allowed, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}")
                # –ü—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å Referer
                headers['Referer'] = 'https://www.boataround.com/'
                continue
            elif response.status_code == 429:
                logger.warning(f"[Requests] 429 Too Many Requests, –∂–¥–µ–º...")
                time.sleep(10)
                continue
            else:
                logger.error(f"[Requests] –°—Ç–∞—Ç—É—Å {response.status_code}")
                response.raise_for_status()
                
        except requests.exceptions.Timeout:
            logger.error(f"[Requests] Timeout –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")
            continue
        except requests.exceptions.ConnectionError as e:
            logger.error(f"[Requests] Connection error: {e}")
            continue
        except requests.exceptions.RequestException as e:
            logger.error(f"[Requests] Request error: {e}")
            continue
        except Exception as e:
            logger.error(f"[Requests] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            continue
    
    logger.error(f"[Requests] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
    return None


# =============================================================================
# –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô
# =============================================================================

def _extract_pictures_from_gallery_component(soup: BeautifulSoup) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ Vue-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ <gallery-mobile :gallery='[...]'>"""
    pics = []
    
    gallery_mobile = soup.find('gallery-mobile')
    if not gallery_mobile:
        logger.warning("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç gallery-mobile –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return pics
    
    gallery_json = gallery_mobile.get(':gallery')
    if not gallery_json:
        logger.warning("–ê—Ç—Ä–∏–±—É—Ç :gallery –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return pics
    
    try:
        gallery_data = json.loads(gallery_json)
        
        for item in gallery_data:
            path = item.get('path', '')
            if path:
                path = path.replace('\\/', '/')
                if path.startswith('boats/'):
                    pics.append(path)
        
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(pics)} —Ñ–æ—Ç–æ –∏–∑ gallery-mobile")
        
    except json.JSONDecodeError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
    
    return pics


def _extract_pictures_fallback(html_content: str) -> list:
    """–ó–∞–ø–∞—Å–Ω–æ–π –º–µ—Ç–æ–¥ ‚Äî regex."""
    pics = set()
    pattern = re.compile(r'boats/([a-f0-9]{24})/([a-f0-9]+)\.(jpg|jpeg|png|webp)', re.IGNORECASE)
    
    for match in pattern.finditer(html_content):
        folder_id = match.group(1)
        image_id = match.group(2)
        ext = match.group(3).lower()
        pics.add(f"boats/{folder_id}/{image_id}.{ext}")
    
    return list(pics)


def extract_pictures(html_content: str, soup: BeautifulSoup = None) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —è—Ö—Ç—ã."""
    if soup is None:
        soup = BeautifulSoup(html_content, 'html.parser')
    
    pics = _extract_pictures_from_gallery_component(soup)
    
    if not pics:
        logger.warning("–ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –¥–ª—è —Ñ–æ—Ç–æ")
        pics = _extract_pictures_fallback(html_content)
    
    return pics


# =============================================================================
# –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –£–°–õ–£–ì –ò –†–ê–°–•–û–î–û–í (extras)
# =============================================================================

def _extract_extras_from_component(soup: BeautifulSoup) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —É—Å–ª—É–≥–∏ –∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ <extras-list :extras='[...]'>"""
    extras = []
    
    extras_list = soup.find('extras-list')
    if not extras_list:
        logger.warning("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç extras-list –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return extras
    
    extras_json = extras_list.get(':extras')
    if extras_json:
        try:
            extras_data = json.loads(extras_json)
            for item in extras_data:
                extra = {
                    'id': item.get('id', ''),
                    'name': item.get('name', ''),
                    'slug': item.get('slug', ''),
                    'additional_info': item.get('additional_info', ''),
                    'unit': item.get('unit', ''),
                    'price': item.get('price', {}).get('amount', 0) if isinstance(item.get('price'), dict) else item.get('price', 0),
                    'price_nice': item.get('price', {}).get('nice', '') if isinstance(item.get('price'), dict) else '',
                    'currency': item.get('price', {}).get('currency', 'EUR') if isinstance(item.get('price'), dict) else 'EUR',
                    'deposit': item.get('deposit', {}).get('amount', 0) if isinstance(item.get('deposit'), dict) else 0,
                    'mandatory': item.get('mandatory', False),
                    'pay_when': item.get('pay_when', ''),
                    'insurance': item.get('insurance', False),
                    'amount_with_label': item.get('amount_with_label', ''),
                }
                extras.append(extra)
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(extras)} —É—Å–ª—É–≥ –∏–∑ :extras")
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ :extras JSON: {e}")
    
    return extras


def _extract_additional_services_from_component(soup: BeautifulSoup) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏ –∏–∑ :additional-services"""
    services = []
    
    extras_list = soup.find('extras-list')
    if not extras_list:
        return services
    
    services_json = extras_list.get(':additional-services')
    if services_json:
        try:
            services_data = json.loads(services_json)
            for item in services_data:
                service = {
                    'name': item.get('name', ''),
                    'slug': item.get('slug', ''),
                    'amount_with_unit': item.get('amountWithUnit', ''),
                    'amount': item.get('amount', 0),
                    'amount_type': item.get('amountType', ''),
                    'disclaimer': item.get('disclaimer', ''),
                    'badge': item.get('badge', ''),
                    'unit': item.get('unit', ''),
                }
                services.append(service)
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(services)} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É—Å–ª—É–≥")
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ :additional-services JSON: {e}")
    
    return services


def _extract_delivery_extras(soup: BeautifulSoup) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —É—Å–ª—É–≥–∏ –¥–æ—Å—Ç–∞–≤–∫–∏ –∏–∑ :extras-delivery"""
    delivery = []
    
    extras_list = soup.find('extras-list')
    if not extras_list:
        return delivery
    
    delivery_json = extras_list.get(':extras-delivery')
    if delivery_json:
        try:
            delivery_data = json.loads(delivery_json)
            for item in delivery_data:
                d = {
                    'name': item.get('name', ''),
                    'additional_info': item.get('additional_info', ''),
                    'unit': item.get('unit', ''),
                    'price': item.get('price', {}).get('amount', 0) if isinstance(item.get('price'), dict) else item.get('price', 0),
                }
                delivery.append(d)
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(delivery)} —É—Å–ª—É–≥ –¥–æ—Å—Ç–∞–≤–∫–∏")
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ :extras-delivery JSON: {e}")
    
    return delivery


# =============================================================================
# –ò–ó–í–õ–ï–ß–ï–ù–ò–ï "–ù–ï –í–ö–õ–Æ–ß–ï–ù–û –í –¶–ï–ù–£"
# =============================================================================

def _extract_not_included(soup: BeautifulSoup) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å–µ–∫—Ü–∏–∏ "–ù–µ –≤–∫–ª—é—á–µ–Ω–æ –≤ —Ü–µ–Ω—É" """
    not_included = []
    
    all_extras_lists = soup.find_all('div', class_='extras-list')
    
    for block in all_extras_lists:
        classes = block.get('class', [])
        
        if 'excluded' in classes:
            items = block.find_all('div', class_='extra-item')
            
            for item in items:
                heading = item.find('li', class_='extra-item__heading')
                price_div = item.find('div', class_='extra-item__price')
                type_span = item.find('span', class_=re.compile(r'extra-item__type--'))
                desc = item.find('div', class_='extra-item__description')
                
                entry = {
                    'name': heading.get_text(strip=True) if heading else '',
                    'price': price_div.get_text(strip=True) if price_div else '',
                    'option': type_span.get_text(strip=True) if type_span else '',
                    'description': desc.get_text(strip=True) if desc else '',
                }
                
                if entry['name']:
                    not_included.append(entry)
    
    logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(not_included)} –ø–æ–∑–∏—Ü–∏–π '–ù–µ –≤–∫–ª—é—á–µ–Ω–æ –≤ —Ü–µ–Ω—É'")
    return not_included


# =============================================================================
# –õ–û–ö–ê–õ–ò–ó–ê–¶–ò–Ø: URL –ò –¢–ï–ö–°–¢–û–í–´–ï –ü–û–õ–Ø –î–õ–Ø –†–ê–ó–ù–´–• –Ø–ó–´–ö–û–í
# =============================================================================

# =============================================================================
# –õ–û–ö–ê–õ–ò–ó–ê–¶–ò–Ø: EXTRAS, SERVICES –ò –ü–†–û–ß–ò–ï –£–°–õ–£–ì–ò –î–õ–Ø –†–ê–ó–ù–´–• –Ø–ó–´–ö–û–í
# =============================================================================

def _extract_extras_for_language(slug: str, lang: str) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç extras, additional_services, delivery_extras –∏ not_included –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —è–∑—ã–∫–∞
    
    Args:
        slug: Slug –ª–æ–¥–∫–∏
        lang: –ö–æ–¥ —è–∑—ã–∫–∞ (ru_RU, en_EN, de_DE –∏ —Ç.–¥.)
    
    Returns:
        dict: {'extras': [...], 'additional_services': [...], 'delivery_extras': [...], 'not_included': [...]}
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º URL –¥–ª—è —è–∑—ã–∫–∞
        url = get_boat_url_for_language(slug, lang)
        url = add_currency_param(url, 'EUR')
        
        logger.info(f"[parser] üåê –ü–∞—Ä—Å–∏–º services –¥–ª—è {lang}: {url}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        html_content = fetch_page(url)
        if not html_content:
            logger.warning(f"[parser] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è {lang}")
            return {
                'extras': [],
                'additional_services': [],
                'delivery_extras': [],
                'not_included': [],
            }
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ª—É–≥
        extras = _extract_extras_from_component(soup)
        additional_services = _extract_additional_services_from_component(soup)
        delivery_extras = _extract_delivery_extras(soup)
        not_included = _extract_not_included(soup)
        
        logger.info(f"[parser] ‚úÖ –ü–æ–ª—É—á–µ–Ω—ã services –¥–ª—è {lang}: extras={len(extras)}, adds={len(additional_services)}, delivery={len(delivery_extras)}, not_included={len(not_included)}")
        
        return {
            'extras': extras,
            'additional_services': additional_services,
            'delivery_extras': delivery_extras,
            'not_included': not_included,
        }
        
    except Exception as e:
        logger.warning(f"[parser] ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ services –¥–ª—è {lang}: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return {
            'extras': [],
            'additional_services': [],
            'delivery_extras': [],
            'not_included': [],
        }


def _extract_extras_from_all_languages(slug: str, languages: list = None) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç services (extras, adds, delivery, not_included) —Å–æ –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤
    
    Args:
        slug: Slug –ª–æ–¥–∫–∏
        languages: –°–ø–∏—Å–æ–∫ —è–∑—ã–∫–æ–≤
    
    Returns:
        dict: {'ru_RU': {'extras': [...], 'additional_services': [...], ...}, ...}
    """
    if languages is None:
        languages = ['ru_RU', 'en_EN', 'de_DE', 'fr_FR']
    
    result = {}
    
    for lang in languages:
        try:
            services = _extract_extras_for_language(slug, lang)
            result[lang] = services
        except Exception as e:
            logger.error(f"[parser] –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è services –¥–ª—è {lang}: {e}")
            result[lang] = {
                'extras': [],
                'additional_services': [],
                'delivery_extras': [],
                'not_included': [],
            }
    
    return result


def get_boat_url_for_language(slug: str, lang: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç URL –ª–æ–¥–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —è–∑—ã–∫–∞
    
    Args:
        slug: Slug –ª–æ–¥–∫–∏
        lang: –ö–æ–¥ —è–∑—ã–∫–∞ (ru_RU, en_EN, de_DE, fr_FR, es_ES)
    
    Returns:
        str: URL —Ç–∏–ø–∞ https://www.boataround.com/{locale}/yacht-type/{slug}/
    """
    # –ú–∞–ø–ø–∏–Ω–≥ —è–∑—ã–∫–æ–≤ –Ω–∞ –ª–æ–∫–∞–ª–∏ –∏ —Ç–∏–ø—ã —è—Ö—Ç
    LANGUAGE_MAPPING = {
        'ru_RU': ('ru', 'yachta'),      # –†—É—Å—Å–∫–∏–π
        'en_EN': ('us', 'boat'),         # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π (–°–®–ê)
        'de_DE': ('de', 'boot'),         # –ù–µ–º–µ—Ü–∫–∏–π
        'fr_FR': ('fr', 'bateau'),       # –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π
        'es_ES': ('es', 'bote'),         # –ò—Å–ø–∞–Ω—Å–∫–∏–π
    }
    
    locale, boat_type = LANGUAGE_MAPPING.get(lang, ('ru', 'yachta'))  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä—É—Å—Å–∫–∏–π
    return f"https://www.boataround.com/{locale}/{boat_type}/{slug}/"


def _extract_boat_info_for_language(slug: str, lang: str) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–æ–¥–∫–µ —Å HTML –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —è–∑—ã–∫–∞
    
    Args:
        slug: Slug –ª–æ–¥–∫–∏
        lang: –ö–æ–¥ —è–∑—ã–∫–∞ (ru_RU, en_EN, de_DE –∏ —Ç.–¥.)
    
    Returns:
        dict: –õ–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (title, description, location, marina)
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º URL –¥–ª—è —è–∑—ã–∫–∞
        url = get_boat_url_for_language(slug, lang)
        url = add_currency_param(url, 'EUR')
        
        logger.info(f"[parser] üåê –ü–∞—Ä—Å–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è {lang}: {url}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        html_content = fetch_page(url)
        if not html_content:
            logger.warning(f"[parser] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è {lang}")
            return {
                'title': '',
                'description': '',
                'location': '',
                'marina': '',
            }
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'title': '',
            'description': '',
            'location': '',
            'marina': '',
        }
        
        # === TITLE ===
        # –ú–µ—Ç–æ–¥ 1: –ò–∑ JSON-LD (schema.org)
        script_tags = soup.find_all('script', {'type': 'application/ld+json'})
        for script in script_tags:
            try:
                data = json.loads(script.string)
                if isinstance(data, dict):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º @graph
                    if '@graph' in data:
                        for item in data.get('@graph', []):
                            if isinstance(item, dict) and item.get('@type') == 'Product':
                                result['title'] = item.get('name', result['title'])
                                result['description'] = item.get('description', result['description'])
                                break
                    # –ò–ª–∏ –ø—Ä—è–º–æ–π Product
                    elif data.get('@type') == 'Product':
                        result['title'] = data.get('name', result['title'])
                        result['description'] = data.get('description', result['description'])
                    
                    if result['title']:
                        break
            except (json.JSONDecodeError, TypeError):
                continue
        
        # === LOCATION –ò MARINA ===
        # –ò–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        add_to_wishlist = soup.find('add-to-wishlist')
        if add_to_wishlist:
            result['marina'] = add_to_wishlist.get('marina', result['marina']) or result['marina']
            result['location'] = add_to_wishlist.get('region', result['location']) or result['location']
        
        # Fallback: –ò–∑ mobile-payment-box
        if not result['location']:
            payment_box = soup.find('mobile-payment-box')
            if payment_box:
                result['location'] = payment_box.get('region', result['location']) or result['location']
        
        logger.info(f"[parser] ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è {lang}: title='{result['title'][:50]}...'")
        
        return result
        
    except Exception as e:
        logger.warning(f"[parser] ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è {lang}: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return {
            'title': '',
            'description': '',
            'location': '',
            'marina': '',
        }


def _extract_boat_info_from_all_languages(slug: str, languages: list = None) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–æ–¥–∫–µ —Å–æ –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤
    
    Args:
        slug: Slug –ª–æ–¥–∫–∏
        languages: –°–ø–∏—Å–æ–∫ —è–∑—ã–∫–æ–≤
    
    Returns:
        dict: {'ru_RU': {'title': ..., 'description': ..., ...}, ...}
    """
    if languages is None:
        languages = ['ru_RU', 'en_EN', 'de_DE', 'fr_FR']
    
    result = {}
    
    for lang in languages:
        try:
            info = _extract_boat_info_for_language(slug, lang)
            result[lang] = info
        except Exception as e:
            logger.error(f"[parser] –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è {lang}: {e}")
            result[lang] = {
                'title': '',
                'description': '',
                'location': '',
                'marina': '',
            }
    
    return result


def _extract_equipment_from_api(slug: str, languages: list = None) -> dict:
    """
    –ü–æ–ª—É—á–∞–µ—Ç equipment –∏–∑ API boataround.com –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö
    
    Args:
        slug: Slug –ª–æ–¥–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä 'beneteau-oceanis-341-ersa')
        languages: –°–ø–∏—Å–æ–∫ —è–∑—ã–∫–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä ['ru_RU', 'en_EN', 'de_DE'])
    
    Returns:
        dict: {'ru_RU': {'cockpit': [...], 'entertainment': [...], 'equipment': [...]}, ...}
    """
    if languages is None:
        languages = ['ru_RU', 'en_EN', 'de_DE', 'fr_FR']
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
    if BoataroundAPI is None:
        from boats.boataround_api import BoataroundAPI as API_CLASS
    else:
        API_CLASS = BoataroundAPI
    
    result = {}
    
    for lang in languages:
        try:
            logger.info(f"[parser] üåê –ü–æ–ª—É—á–∞—é equipment –∏–∑ API –¥–ª—è slug={slug}, lang={lang}")
            
            # –í—ã–∑—ã–≤–∞–µ–º –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ API
            # API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {'status': 'OK', 'data': [{'_id': ..., 'data': [...], 'filter': {...}, ...}]}
            response_data = requests.get(
                'https://api.boataround.com/v1/search',
                params={
                    'slug': slug,
                    'lang': lang,
                    'limit': 1,
                },
                headers=API_CLASS.HEADERS,
                timeout=30
            ).json()
            
            logger.debug(f"[parser] API response keys: {list(response_data.keys())}")
            
            if response_data and isinstance(response_data, dict):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
                # –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {'status': 'OK', 'data': [{'filter': {...}, ...}]}
                data_list = response_data.get('data', [])
                
                if isinstance(data_list, list) and len(data_list) > 0:
                    search_group = data_list[0]  # –ü–µ—Ä–≤–∞—è –≥—Ä—É–ø–ø–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    filter_data = search_group.get('filter', {})  # ‚≠ê filters –Ω–∞ —É—Ä–æ–≤–Ω–µ –≥—Ä—É–ø–ø—ã
                    
                    logger.debug(f"[parser] filter_data type: {type(filter_data)}, keys: {list(filter_data.keys()) if isinstance(filter_data, dict) else 'N/A'}")
                    
                    if isinstance(filter_data, dict) and filter_data:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º cockpit
                        cockpit = []
                        if 'cockpit' in filter_data and isinstance(filter_data['cockpit'], list):
                            cockpit = [{'name': item.get('name', '')} for item in filter_data['cockpit'] if item.get('name')]
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º entertainment
                        entertainment = []
                        if 'entertainment' in filter_data and isinstance(filter_data['entertainment'], list):
                            entertainment = [{'name': item.get('name', '')} for item in filter_data['entertainment'] if item.get('name')]
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º equipment
                        equipment = []
                        if 'equipment' in filter_data and isinstance(filter_data['equipment'], list):
                            equipment = [{'name': item.get('name', '')} for item in filter_data['equipment'] if item.get('name')]
                        
                        result[lang] = {
                            'cockpit': cockpit,
                            'entertainment': entertainment,
                            'equipment': equipment,
                        }
                        logger.info(f"[parser] ‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –¥–ª—è {lang}: cockpit={len(cockpit)}, entertainment={len(entertainment)}, equipment={len(equipment)}")
                    else:
                        logger.warning(f"[parser] filter_data –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ dict –¥–ª—è {lang}")
                        result[lang] = {'cockpit': [], 'entertainment': [], 'equipment': []}
                else:
                    logger.warning(f"[parser] API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ data –¥–ª—è {lang}")
                    result[lang] = {'cockpit': [], 'entertainment': [], 'equipment': []}
            else:
                logger.warning(f"[parser] response_data –Ω–µ —è–≤–ª—è–µ—Ç—Å—è dict –∏–ª–∏ –ø—É—Å—Ç–æ –¥–ª—è {lang}")
                result[lang] = {'cockpit': [], 'entertainment': [], 'equipment': []}
                
        except Exception as e:
            logger.warning(f"[parser] ‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è equipment –¥–ª—è {lang}: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            result[lang] = {'cockpit': [], 'entertainment': [], 'equipment': []}
    
    return result


# =============================================================================
# –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –û–ë–û–†–£–î–û–í–ê–ù–ò–Ø (Cockpit, Entertainment, Equipment)
# =============================================================================

def _extract_equipment_section(soup: BeautifulSoup, section_key: str) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –∏–∑ vue –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ (cockpit, entertainment, equipment)"""
    items = []
    
    extras_list = soup.find('extras-list')
    if not extras_list:
        return items
    
    # –ò—â–µ–º –∞—Ç—Ä–∏–±—É—Ç :cockpit, :entertainment –∏–ª–∏ :equipment
    attr_name = f':{section_key}'
    section_json = extras_list.get(attr_name)
    
    if section_json:
        try:
            section_data = json.loads(section_json)
            for item in section_data:
                entry = {
                    'name': item.get('name', ''),
                    'slug': item.get('slug', ''),
                    'additional_info': item.get('additional_info', ''),
                    'unit': item.get('unit', ''),
                    'price': item.get('price', {}).get('amount', 0) if isinstance(item.get('price'), dict) else item.get('price', 0),
                    'price_nice': item.get('price', {}).get('nice', '') if isinstance(item.get('price'), dict) else '',
                    'currency': item.get('price', {}).get('currency', 'EUR') if isinstance(item.get('price'), dict) else 'EUR',
                    'mandatory': item.get('mandatory', False),
                    'pay_when': item.get('pay_when', ''),
                }
                if entry['name']:
                    items.append(entry)
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–∑ {section_key}")
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ :{section_key} JSON: {e}")
    else:
        logger.debug(f"–ê—Ç—Ä–∏–±—É—Ç :{section_key} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ extras-list")
    
    return items


# =============================================================================
# –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –¶–ï–ù
# =============================================================================

def _extract_prices(soup: BeautifulSoup, html_content: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ü–µ–Ω."""
    prices = {
        'low_price': None,
        'currency': 'EUR',
        'min_price': None,
        'total_price': None,
        'old_price': None,
        'discount': None,
    }
    
    # –ú–µ—Ç–æ–¥ 1: –ò–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ mobile-payment-box
    payment_box = soup.find('mobile-payment-box')
    if payment_box:
        price_attr = payment_box.get(':price')
        if price_attr and price_attr != 'price':
            try:
                prices['min_price'] = int(price_attr)
                prices['total_price'] = int(price_attr)
                logger.info(f"–¶–µ–Ω–∞ –∏–∑ :price: {prices['total_price']}")
            except (ValueError, TypeError):
                pass
        
        old_price_attr = payment_box.get(':old-price')
        if old_price_attr and old_price_attr != 'oldPrice':
            try:
                prices['old_price'] = int(old_price_attr)
                logger.info(f"–°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞ –∏–∑ :old-price: {prices['old_price']}")
            except (ValueError, TypeError):
                pass
        
        discount_attr = payment_box.get(':discount')
        if discount_attr and discount_attr != 'discount':
            try:
                prices['discount'] = int(discount_attr)
                logger.info(f"–°–∫–∏–¥–∫–∞ –∏–∑ :discount: {prices['discount']}")
            except (ValueError, TypeError):
                pass
    
    # –ú–µ—Ç–æ–¥ 2: –ò–∑ —Ç–µ–∫—Å—Ç–∞ HTML (regex)
    if not prices['total_price']:
        # –ò—â–µ–º —Ü–µ–Ω—ã –≤–∏–¥–∞ "1 234 ‚Ç¨" –∏–ª–∏ "1234‚Ç¨"
        price_patterns = [
            r'total["\']?\s*:\s*["\']?(\d+)',
            r'price["\']?\s*:\s*["\']?(\d+)',
            r'(\d[\d\s]{2,})\s*‚Ç¨',
            r'‚Ç¨\s*(\d[\d\s]{2,})',
        ]
        
        for pattern in price_patterns:
            matches = re.findall(pattern, html_content)
            if matches:
                try:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
                    price_str = matches[0].replace(' ', '').replace(',', '')
                    price = int(price_str)
                    if 100 < price < 100000:  # –†–∞–∑—É–º–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
                        prices['total_price'] = price
                        prices['min_price'] = price
                        logger.info(f"–¶–µ–Ω–∞ –∏–∑ regex: {price}")
                        break
                except (ValueError, IndexError):
                    continue
    
    # –ú–µ—Ç–æ–¥ 3: –ò–∑ JSON –≤ HTML
    if not prices['total_price']:
        # –ò—â–µ–º JSON-–±–ª–æ–∫–∏ —Å —Ü–µ–Ω–∞–º–∏
        json_pattern = r'price["\']?\s*:\s*["\']?(\d+)'
        matches = re.findall(json_pattern, html_content)
        if matches:
            try:
                price = int(matches[0])
                if 100 < price < 100000:
                    prices['total_price'] = price
                    prices['min_price'] = price
                    logger.info(f"–¶–µ–Ω–∞ –∏–∑ JSON: {price}")
            except (ValueError, IndexError):
                pass
    
    # –ï—Å–ª–∏ –Ω–µ—Ç —Ü–µ–Ω—ã - –æ—à–∏–±–∫–∞
    if not prices['total_price']:
        logger.warning("‚ö†Ô∏è –¶–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
    
    return prices


# =============================================================================
# –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ë–ê–ó–û–í–û–ô –ò–ù–§–û–†–ú–ê–¶–ò–ò –û –Ø–•–¢–ï
# =============================================================================

def _extract_boat_info(soup: BeautifulSoup, html_content: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —è—Ö—Ç–µ."""
    info = {
        'title': '',
        'manufacturer': '',
        'model': '',
        'year': '',
        'cabins': '',
        'toilets': '',
        'people': '',
        'length': '',
        'location': '',
        'marina': '',
        'country': '',
        'description': '',
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        'beam': '',
        'draft': '',
        'engine_type': '',
        'fuel': '',
        'maximum_speed': '',
        'cruising_consumption': '',
        'renovated_year': '',
        'sail_renovated_year': '',
        'max_sleeps': '',
        'max_people': '',
        'single_cabins': '',
        'double_cabins': '',
        'triple_cabins': '',
        'quadruple_cabins': '',
        'cabins_with_bunk_bed': '',
        'saloon_sleeps': '',
        'crew_sleeps': '',
        'electric_toilets': '',
    }
    
    # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ JSON-LD (schema.org)
    script_tags = soup.find_all('script', {'type': 'application/ld+json'})
    logger.info(f"[parser] Found {len(script_tags)} JSON-LD scripts")
    
    for script_idx, script in enumerate(script_tags):
        try:
            data = json.loads(script.string)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
            if isinstance(data, list):
                logger.info(f"[parser] Script {script_idx}: list with {len(data)} items")
                for item_idx, item in enumerate(data):
                    if isinstance(item, dict):
                        item_type = item.get('@type', 'unknown')
                        logger.info(f"[parser] Script {script_idx} Item {item_idx}: @type={item_type}")
                        if item.get('@type') == 'Product':
                            info['title'] = item.get('name', info['title'])
                            info['description'] = item.get('description', info['description'])
                            info['manufacturer'] = item.get('manufacturer', {}).get('name', info['manufacturer']) if isinstance(item.get('manufacturer'), dict) else item.get('brand', {}).get('name', info['manufacturer']) if isinstance(item.get('brand'), dict) else info['manufacturer']
                            info['model'] = item.get('model', info['model'])
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –µ—Å—Ç—å
                            info['beam'] = item.get('beam', info['beam']) or ''
                            info['draft'] = item.get('draft', info['draft']) or ''
                            logger.info(f"[parser] ‚úÖ Extracted from schema.org: title='{info['title']}'")
                            break
                            
            elif isinstance(data, dict):
                data_type = data.get('@type', 'unknown')
                logger.info(f"[parser] Script {script_idx}: dict @type={data_type}")
                
                # –ï—Å–ª–∏ —ç—Ç–æ @graph, –∏—â–µ–º Product –≤–Ω—É—Ç—Ä–∏
                if data.get('@context') == 'https://schema.org' or '@graph' in data:
                    items = data.get('@graph', [data])
                    if not isinstance(items, list):
                        items = [items]
                    logger.info(f"[parser] Searching in graph: {len(items)} items")
                    for item in items:
                        if isinstance(item, dict) and item.get('@type') == 'Product':
                            info['title'] = item.get('name', info['title'])
                            info['description'] = item.get('description', info['description'])
                            info['model'] = item.get('model', info['model'])
                            logger.info(f"[parser] ‚úÖ Extracted from @graph Product: title='{info['title']}'")
                            break
                
                elif data.get('@type') == 'Product':
                    info['title'] = data.get('name', info['title'])
                    info['description'] = data.get('description', info['description'])
                    info['manufacturer'] = data.get('manufacturer', {}).get('name', info['manufacturer']) if isinstance(data.get('manufacturer'), dict) else data.get('brand', {}).get('name', info['manufacturer']) if isinstance(data.get('brand'), dict) else info['manufacturer']
                    info['model'] = data.get('model', info['model'])
                    logger.info(f"[parser] ‚úÖ Extracted from schema.org: title='{info['title']}'")
                    
        except (json.JSONDecodeError, TypeError, AttributeError) as e:
            logger.warning(f"[parser] Failed to parse JSON-LD script {script_idx}: {e}")
            continue
    
    # Fallback: –∏–∑ —Å—Ç–∞—Ä—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–µ—Å–ª–∏ –µ—â–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç)
    payment_box = soup.find('mobile-payment-box')
    if payment_box:
        logger.info(f"[parser] Found mobile-payment-box")
        info['title'] = payment_box.get('boat-title', info['title']) or info['title']
        info['year'] = payment_box.get('boat-year', '')
        info['cabins'] = payment_box.get('boat-cabins', '')
        info['people'] = payment_box.get('boat-people', '')
        info['length'] = payment_box.get('boat-length', '')
        info['manufacturer'] = payment_box.get('manufacturer', '')
        info['country'] = payment_box.get('country', '')
        info['location'] = payment_box.get('region', '')
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        info['beam'] = payment_box.get('boat-beam', '')
        info['draft'] = payment_box.get('boat-draft', '')
        info['engine_type'] = payment_box.get('boat-engine-type', '')
        info['fuel'] = payment_box.get('boat-fuel', '')
        info['maximum_speed'] = payment_box.get('boat-max-speed', '')
        info['toilets'] = payment_box.get('boat-toilets', '')
    else:
        logger.warning(f"[parser] payment_box –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    
    # –ò–∑ boat-info-list –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ (–æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ÊäÄ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
    boat_info_list = soup.find('boat-info-list')
    if boat_info_list:
        params_str = boat_info_list.get(':parameters', '{}')
        try:
            params = json.loads(params_str)
            logger.info(f"[parser] ‚úÖ boat-info-list –Ω–∞–π–¥–µ–Ω —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: {list(params.keys())[:10]}")
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            info['single_cabins'] = str(params.get('single_cabins', ''))
            info['double_cabins'] = str(params.get('double_cabins', ''))
            info['triple_cabins'] = str(params.get('triple_cabins', ''))
            info['quadruple_cabins'] = str(params.get('quadruple_cabins', ''))
            info['cabins_with_bunk_bed'] = str(params.get('cabins_with_bunk_bed', ''))
            info['saloon_sleeps'] = str(params.get('saloon_sleeps', ''))
            info['crew_sleeps'] = str(params.get('crew_sleeps', ''))
            info['max_sleeps'] = str(params.get('max_sleeps', ''))
            info['max_people'] = str(params.get('max_people', ''))
            info['toilets'] = str(params.get('toilets', info['toilets']))
            info['electric_toilets'] = str(params.get('electric_toilets', ''))
            info['length'] = str(params.get('length', ''))
            info['beam'] = str(params.get('beam', ''))
            info['draft'] = str(params.get('draft', ''))
            info['engine_power'] = str(params.get('engine_power', ''))
            info['number_engines'] = str(params.get('number_engines', ''))
            info['total_engine_power'] = str(params.get('total_engine_power', ''))
            info['engine'] = str(params.get('engine', ''))
            info['fuel'] = str(params.get('fuel', ''))
            info['cruising_consumption'] = str(params.get('cruising_consumption', ''))
            info['maximum_speed'] = str(params.get('maximum_speed', ''))
            info['water_tank'] = str(params.get('water_tank', ''))
            info['waste_tank'] = str(params.get('waste_tank', ''))
            info['year'] = str(params.get('year', info['year']))
            info['renovated_year'] = str(params.get('renovated_year', ''))
            info['sail_renovated_year'] = str(params.get('sail_renovated_year', ''))
            info['cabins'] = str(params.get('cabins', info['cabins']))
        except (json.JSONDecodeError, TypeError) as e:
            logger.warning(f"[parser] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ boat-info-list params: {e}")
    else:
        logger.warning(f"[parser] boat-info-list –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    
    # –ò–∑ add-to-wishlist (fallback)
    wishlist = soup.find('add-to-wishlist')
    if wishlist:
        info['marina'] = wishlist.get('marina', info['marina']) or info['marina']
        if not info['year']:
            info['year'] = wishlist.get('year', '')
        if not info['cabins']:
            info['cabins'] = wishlist.get('cabins', '')
    
    # FALLBACK: –ï—Å–ª–∏ manufacturer –ø—É—Å—Ç–æ–π, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ title
    if not info['manufacturer'] and info['title']:
        # Title –æ–±—ã—á–Ω–æ "Lagoon 380 S2 | Aride", manufacturer - –¥–æ |
        parts = info['title'].split('|')
        if len(parts) > 0:
            potential_manufacturer = parts[0].strip()
            # –ï—Å–ª–∏ –≤ manufacturer –µ—Å—Ç—å –¥–≤–µ —á–∞—Å—Ç–∏ (manufacturer + model), –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é
            model_parts = potential_manufacturer.split()
            if len(model_parts) > 0:
                info['manufacturer'] = model_parts[0]  # –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ - –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å
    
    logger.info(f"[parser] Final boat_info: {info}")
    return info


def _extract_boat_id(html_content: str) -> Optional[str]:
    match = BOAT_ID_PATTERN.search(html_content)
    return match.group(1) if match else None


# =============================================================================
# –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò
# =============================================================================

def parse_boataround_url(url: str, save_to_db: bool = True) -> Optional[dict]:
    """
    –ü–∞—Ä—Å–∏—Ç URL —Å boataround.com –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ª–æ–¥–∫–µ.
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Django.
    
    Args:
        url: URL —Å boataround.com
        save_to_db: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ ParsedBoat
    
    Returns:
        dict: –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –ª–æ–¥–∫–µ
    """
    from urllib.parse import urlparse, parse_qs
    
    # ‚≠ê –ì–õ–ê–í–ù–û–ï: –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä currency=EUR —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—ã –≤ –µ–≤—Ä–æ
    url = add_currency_param(url, 'EUR')
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ URL
    parsed = urlparse(url)
    query_params = parse_qs(parsed.query)
    
    check_in = query_params.get('checkIn', [''])[0]
    check_out = query_params.get('checkOut', [''])[0]
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º slug
    match = SLUG_FROM_URL_PATTERN.search(url)
    slug = match.group(1) if match else 'unknown'
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
    html_content = fetch_page(url)
    if not html_content:
        return None
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    boat_id = _extract_boat_id(html_content)
    pics = extract_pictures(html_content, soup)
    boat_info = _extract_boat_info(soup, html_content)
    prices = _extract_prices(soup, html_content)
    extras = _extract_extras_from_component(soup)
    additional_services = _extract_additional_services_from_component(soup)
    delivery_extras = _extract_delivery_extras(soup)
    not_included = _extract_not_included(soup)
    
    # ‚≠ê –ü–æ–ª—É—á–∞–µ–º equipment –∏–∑ API –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö
    SUPPORTED_LANGUAGES = ['ru_RU', 'en_EN', 'de_DE', 'fr_FR', 'es_ES']
    equipment_by_language = _extract_equipment_from_api(slug, SUPPORTED_LANGUAGES)
    
    # ‚≠ê –ü–æ–ª—É—á–∞–µ–º –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑ HTML —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤
    localized_descriptions = _extract_boat_info_from_all_languages(slug, SUPPORTED_LANGUAGES)
    
    # ‚≠ê –ü–æ–ª—É—á–∞–µ–º –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏ (extras, adds, delivery, not_included) –∏–∑ HTML —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤
    localized_extras = _extract_extras_from_all_languages(slug, SUPPORTED_LANGUAGES)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –ø—É—Å—Ç—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    # –ë—É–¥—É—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –∏–∑ API –Ω–∏–∂–µ
    cockpit = equipment_by_language.get('ru_RU', {}).get('cockpit', [])
    entertainment = equipment_by_language.get('ru_RU', {}).get('entertainment', [])
    equipment = equipment_by_language.get('ru_RU', {}).get('equipment', [])
    
    # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ (–ø–µ—Ä–≤—ã–µ 20)
    pics_to_download = pics[:20]
    downloaded_pics = []
    
    logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ {len(pics_to_download)} —Ñ–æ—Ç–æ...")
    for pic_path in pics_to_download:
        saved_path = download_and_save_image(pic_path)
        if saved_path:
            downloaded_pics.append(saved_path)
    
    logger.info(f"–£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ {len(downloaded_pics)}/{len(pics_to_download)} —Ñ–æ—Ç–æ")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º equipment –Ω–∞ —Ä—É—Å—Å–∫–æ–º –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ (–æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫)
    ru_equipment = equipment_by_language.get('ru_RU', {})
    cockpit = ru_equipment.get('cockpit', [])
    entertainment = ru_equipment.get('entertainment', [])
    equipment_data = ru_equipment.get('equipment', [])
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø–æ–ª–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
    result = {
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        'url': url,
        'slug': slug,
        'boat_id': boat_id,
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏
        'check_in': check_in,
        'check_out': check_out,
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª–æ–¥–∫–µ (–≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
        'boat_info': boat_info,
        
        # –¶–µ–Ω—ã
        'prices': prices,
        
        # –ì–õ–ê–í–ù–û–ï: –§–æ—Ç–æ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        'pictures': downloaded_pics,      # –ü—É—Ç–∏ –≤ /app/media/boats/...
        'gallery': downloaded_pics,       # –°–∏–Ω–æ–Ω–∏–º –¥–ª—è API —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        
        # –£—Å–ª—É–≥–∏ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        'extras': extras,                           # –û—Å–Ω–æ–≤–Ω—ã–µ —É—Å–ª—É–≥–∏ (—Å–∞–ø–±–æ—Ä–¥, –∫–∞–ø–∏—Ç–∞–Ω –∏ —Ç.–¥.)
        'additional_services': additional_services, # –î–æ–ø —É—Å–ª—É–≥–∏ (–≥–∏–±–∫–∞—è –æ—Ç–º–µ–Ω–∞ –∏ —Ç.–¥.)
        'delivery_extras': delivery_extras,         # –£—Å–ª—É–≥–∏ –¥–æ—Å—Ç–∞–≤–∫–∏
        'not_included': not_included,               # –ß—Ç–æ –Ω–µ –≤–∫–ª—é—á–µ–Ω–æ –≤ —Å—Ç–æ–∏–º–æ—Å—Ç—å
        
        # –û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ (–æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ - —Ä—É—Å—Å–∫–∏–π)
        'cockpit': cockpit,                         # –û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –∫–æ–∫–ø–∏—Ç–∞
        'entertainment': entertainment,             # –†–∞–∑–≤–ª–µ—á–µ–Ω–∏—è
        'equipment': equipment_data,                # –û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ
        
        # –û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö (–¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç–∏)
        'equipment_by_language': equipment_by_language,
    }
    # –ö—Ä–∞—Ç–∫–æ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
    try:
        price_val = prices.get('total_price') or prices.get('min_price') or prices.get('low_price') or 0
    except Exception:
        price_val = 0

    logger.info(
        f"[parser-summary] title='{boat_info.get('title','')}', boat_id={boat_id}, "
        f"price={price_val}, images={len(downloaded_pics)}, extras={len(extras)}, "
        f"adds={len(additional_services)}, delivery={len(delivery_extras)}, not_included={len(not_included)}, "
        f"cockpit={len(cockpit)}, entertainment={len(entertainment)}, equipment={len(equipment)}"
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É
    if save_to_db and boat_id and slug:
        try:
            from boats.models import (
                ParsedBoat, BoatTechnicalSpecs, BoatDescription, 
                BoatPrice, BoatGallery, BoatDetails
            )
            from decimal import Decimal
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º ParsedBoat
            parsed_boat, created = ParsedBoat.objects.update_or_create(
                boat_id=boat_id,
                defaults={
                    'slug': slug,
                    'manufacturer': boat_info.get('manufacturer', ''),
                    'model': boat_info.get('model', ''),
                    'year': int(boat_info.get('year', 0)) if boat_info.get('year') else None,
                    'source_url': url,
                }
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (BoatTechnicalSpecs)
            BoatTechnicalSpecs.objects.update_or_create(
                boat=parsed_boat,
                defaults={
                    'length': float(boat_info.get('length', 0)) if boat_info.get('length') else None,
                    'beam': float(boat_info.get('beam', 0)) if boat_info.get('beam') else None,
                    'draft': float(boat_info.get('draft', 0)) if boat_info.get('draft') else None,
                    'cabins': int(boat_info.get('cabins', 0)) if boat_info.get('cabins') else None,
                    'berths': int(boat_info.get('max_sleeps', 0)) if boat_info.get('max_sleeps') else None,
                    'toilets': int(boat_info.get('toilets', 0)) if boat_info.get('toilets') else None,
                    'fuel_capacity': int(boat_info.get('fuel', 0)) if boat_info.get('fuel') else None,
                    'water_capacity': int(boat_info.get('water_tank', 0)) if boat_info.get('water_tank') else None,
                    'max_speed': float(boat_info.get('maximum_speed', 0)) if boat_info.get('maximum_speed') else None,
                    'engine_power': int(boat_info.get('engine_power', 0)) if boat_info.get('engine_power') else None,
                    'number_engines': int(boat_info.get('number_engines', 0)) if boat_info.get('number_engines') else None,
                    'engine_type': boat_info.get('engine_type', ''),
                    'fuel_type': boat_info.get('fuel_type', ''),
                }
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ (BoatDescription) –¥–ª—è –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤
            for language in SUPPORTED_LANGUAGES:
                lang_desc = localized_descriptions.get(language, {})
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ —Ä—É—Å—Å–∫–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                title = lang_desc.get('title', '') or boat_info.get('title', '')
                description = lang_desc.get('description', '') or boat_info.get('description', '')
                location = lang_desc.get('location', '') or boat_info.get('location', '')
                marina = lang_desc.get('marina', '') or boat_info.get('marina', '')
                
                BoatDescription.objects.update_or_create(
                    boat=parsed_boat,
                    language=language,
                    defaults={
                        'title': title,
                        'description': description,
                        'location': location,
                        'marina': marina,
                    }
                )
                logger.info(f"[parser] ‚úÖ BoatDescription —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –¥–ª—è {language}: title='{title[:50]}...'")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ü–µ–Ω—ã (BoatPrice) - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é EUR —Å –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–µ–Ω–æ–π
            if prices and (prices.get('total_price') or prices.get('min_price')):
                price_per_day = prices.get('total_price') or prices.get('min_price') or 0
                if price_per_day and price_per_day > 0:
                    try:
                        BoatPrice.objects.update_or_create(
                            boat=parsed_boat,
                            currency='EUR',  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é EUR
                            defaults={
                                'price_per_day': Decimal(str(price_per_day)),
                                'price_per_week': None,
                            }
                        )
                        logger.info(f"–¶–µ–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {price_per_day} EUR")
                    except Exception as price_err:
                        logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã {price_per_day}: {price_err}")

            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—É—é –≥–∞–ª–µ—Ä–µ—é –∏ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é (BoatGallery)
            BoatGallery.objects.filter(boat=parsed_boat).delete()
            for idx, pic_url in enumerate(downloaded_pics, 1):
                BoatGallery.objects.create(
                    boat=parsed_boat,
                    cdn_url=pic_url,
                    order=idx
                )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–ø. –¥–µ—Ç–∞–ª–∏ (BoatDetails) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞
            for language in SUPPORTED_LANGUAGES:
                lang_equipment = equipment_by_language.get(language, {})
                lang_services = localized_extras.get(language, {})
                
                BoatDetails.objects.update_or_create(
                    boat=parsed_boat,
                    language=language,
                    defaults={
                        # –õ–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞
                        'extras': lang_services.get('extras', []),
                        'additional_services': lang_services.get('additional_services', []),
                        'delivery_extras': lang_services.get('delivery_extras', []),
                        'not_included': lang_services.get('not_included', []),
                        # –õ–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞
                        'cockpit': lang_equipment.get('cockpit', []),
                        'entertainment': lang_equipment.get('entertainment', []),
                        'equipment': lang_equipment.get('equipment', []),
                    }
                )
                logger.info(f"[parser] ‚úÖ BoatDetails —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è {language}: extras={len(lang_services.get('extras', []))}, cockpit={len(lang_equipment.get('cockpit', []))}")

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–∞—Ä—Å–∏–Ω–≥–æ–≤
            if not created:
                parsed_boat.parse_count += 1
                parsed_boat.save(update_fields=['parse_count'])

            action = "—Å–æ–∑–¥–∞–Ω" if created else "–æ–±–Ω–æ–≤–ª–µ–Ω"
            logger.info(f"ParsedBoat {action}: {slug} (ID: {boat_id})")

        except Exception as e:
            import traceback
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ ParsedBoat: {e}\n{traceback.format_exc()}")
    
    return result


# =============================================================================
# –£–¢–ò–õ–ò–¢–´
# =============================================================================

def get_full_image_url(path: str, width: int = 1920, height: int = 1080) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è CDN.
    
    Args:
        path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, –Ω–∞–ø—Ä–∏–º–µ—Ä 'boats/62b96d157a9323583a5a4880/650d96fa43b7cac28800ead4.jpg'
    
    Returns:
        str: https://b1cdn.prvms.ru/static/boats/.../image.jpg
    """
    return get_cdn_url(path)


def get_thumbnail_url(path: str, size: int = 200) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç URL –º–∏–Ω–∏–∞—Ç—é—Ä—ã –¥–ª—è CDN.
    
    Args:
        path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    
    Returns:
        str: https://b1cdn.prvms.ru/static/boats/.../image.jpg
    """
    return get_cdn_url(path)


# =============================================================================
# –ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô –ü–ê–†–°–ï–† (—Ç–æ–ª—å–∫–æ —Ñ–æ—Ç–æ –∏ extras)
# =============================================================================

def parse_boataround_url_minimal(url: str) -> Optional[dict]:
    """
    –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–µ—Ä –∫–æ—Ç–æ—Ä—ã–π –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¢–û–õ–¨–ö–û:
    - –§–æ—Ç–æ (pictures)
    - Extras, additional_services, delivery_extras, not_included
    
    –ù–µ –ø–∞—Ä—Å–∏—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ–Ω–∏ –±–µ—Ä—É—Ç—Å—è –∏–∑ API).
    –ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ñ–æ—Ç–æ –∏ —É—Å–ª—É–≥.
    
    Args:
        url: URL –ª–æ–¥–∫–∏ –Ω–∞ boataround.com
    
    Returns:
        dict: {'pictures': [...], 'extras': [...], ...} –∏–ª–∏ None
    """
    try:
        logger.info(f"[parser-minimal] –ó–∞–≥—Ä—É–∂–∞–µ–º: {url}")
        
        headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        logger.info(f"[parser-minimal] ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(response.content)} –±–∞–π—Ç")
        
        result = {
            'pictures': [],
            'extras': [],
            'additional_services': [],
            'delivery_extras': [],
            'not_included': [],
        }
        
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–æ—Ç–æ –∏–∑ boat-info-list –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
        boat_info_list = soup.find('boat-info-list')
        if boat_info_list:
            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–µ –∏ —Å–∫—Ä–∏–ø—Ç–µ
            pass  # boat-info-list –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ–æ—Ç–æ –Ω–∞–ø—Ä—è–º—É—é
        
        # 2. –ò—â–µ–º gallery-mobile –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è —Ñ–æ—Ç–æ
        gallery = soup.find('gallery-mobile')
        if gallery:
            logger.info(f"[parser-minimal] ‚úÖ –ù–∞–π–¥–µ–Ω gallery-mobile")
            images_attr = gallery.get(':images', '[]')
            try:
                images = json.loads(images_attr)
                if isinstance(images, list):
                    for img in images:
                        if isinstance(img, dict):
                            # –ú–æ–∂–µ—Ç –±—ã—Ç—å url –∏–ª–∏ path
                            pic_url = img.get('url') or img.get('path')
                            if pic_url:
                                result['pictures'].append(pic_url)
                    logger.info(f"[parser-minimal] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(result['pictures'])} —Ñ–æ—Ç–æ")
            except Exception as e:
                logger.warning(f"[parser-minimal] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ gallery images: {e}")
        else:
            logger.warning(f"[parser-minimal] gallery-mobile –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º extras/services –∏–∑ extras-list –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
        extras_list = soup.find('extras-list')
        if extras_list:
            logger.info(f"[parser-minimal] ‚úÖ –ù–∞–π–¥–µ–Ω extras-list")
            
            # –ü–∞—Ä—Å–∏–º extras
            extras_attr = extras_list.get(':extras', '[]')
            try:
                extras = json.loads(extras_attr)
                if isinstance(extras, list):
                    result['extras'] = extras
                    logger.info(f"[parser-minimal] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(extras)} extras")
            except Exception as e:
                logger.warning(f"[parser-minimal] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ extras: {e}")
            
            # –ü–∞—Ä—Å–∏–º additional_services
            services_attr = extras_list.get(':additional-services', '[]')
            try:
                services = json.loads(services_attr)
                if isinstance(services, list):
                    result['additional_services'] = services
                    logger.info(f"[parser-minimal] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(services)} additional_services")
            except Exception as e:
                logger.warning(f"[parser-minimal] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ services: {e}")
            
            # –ü–∞—Ä—Å–∏–º delivery extras
            delivery_attr = extras_list.get(':extras-delivery', '[]')
            try:
                delivery = json.loads(delivery_attr)
                if isinstance(delivery, list):
                    result['delivery_extras'] = delivery
                    logger.info(f"[parser-minimal] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(delivery)} delivery_extras")
            except Exception as e:
                logger.warning(f"[parser-minimal] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ delivery: {e}")
        
        # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º not_included
        # –ò—â–µ–º –≤ description –∏–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ–º –±–ª–æ–∫–µ
        not_included_section = soup.find(class_='not-included') or soup.find(text=re.compile('–Ω–µ –≤–∫–ª—é—á–µ–Ω–æ', re.I))
        if not_included_section:
            logger.info(f"[parser-minimal] –ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è '–Ω–µ –≤–∫–ª—é—á–µ–Ω–æ'")
            # TODO: –ø–∞—Ä—Å–∏—Ç—å —ç—Ç–æ—Ç –±–ª–æ–∫ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        
        logger.info(f"[parser-minimal] ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ: {len(result['pictures'])} —Ñ–æ—Ç–æ, "
                   f"{len(result['extras'])} extras")
        
        return result
        
    except Exception as e:
        logger.error(f"[parser-minimal] ‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None

