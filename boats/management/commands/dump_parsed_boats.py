"""Management command –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–º–ø–∞ –ª–æ–¥–æ–∫ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python manage.py dump_parsed_boats
    python manage.py dump_parsed_boats --output boats_full.json
    python manage.py dump_parsed_boats --split --output-dir boats/fixtures/split/
    python manage.py dump_parsed_boats --parsed-only
"""

import json
import logging
import time
from pathlib import Path

from django.core.serializers import serialize
from django.core.management.base import BaseCommand

from boats.models import (
    Boat,
    BoatDescription,
    BoatDetails,
    BoatGallery,
    BoatPrice,
    BoatTechnicalSpecs,
    Charter,
    ParsedBoat,
)

logger = logging.getLogger(__name__)

BATCH_SIZE = 2000


class Command(BaseCommand):
    help = '–°–æ–∑–¥–∞—ë—Ç –¥–∞–º–ø –≤—Å–µ—Ö –ª–æ–¥–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î –≤ –ø—Ä–æ–¥–µ'

    def add_arguments(self, parser):
        parser.add_argument(
            '--output',
            type=str,
            default='boats/fixtures/parsed_boats.json',
            help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–º–ø–∞ (default: boats/fixtures/parsed_boats.json)',
        )
        parser.add_argument(
            '--output-dir',
            type=str,
            default='boats/fixtures/split',
            help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è split-–¥–∞–º–ø–∞ (default: boats/fixtures/split/)',
        )
        parser.add_argument(
            '--split',
            action='store_true',
            help='–†–∞–∑–±–∏—Ç—å –¥–∞–º–ø –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ –º–æ–¥–µ–ª—è–º',
        )
        parser.add_argument(
            '--parsed-only',
            action='store_true',
            help='–í—ã–≥—Ä—É–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ ParsedBoat (legacy —Ä–µ–∂–∏–º)',
        )
        parser.add_argument(
            '--max-records',
            type=int,
            default=20000,
            help='–ú–∞–∫—Å. –∑–∞–ø–∏—Å–µ–π –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ –ø—Ä–∏ --split (default: 20000)',
        )

    def _get_model_querysets(self, parsed_only):
        if parsed_only:
            return [('boats.parsedboat', ParsedBoat.objects.all())]
        return [
            ('boats.charter', Charter.objects.all()),
            ('boats.boat', Boat.objects.all()),
            ('boats.parsedboat', ParsedBoat.objects.all()),
            ('boats.boattechnicalspecs', BoatTechnicalSpecs.objects.select_related('boat').all()),
            ('boats.boatdescription', BoatDescription.objects.select_related('boat').all()),
            ('boats.boatprice', BoatPrice.objects.select_related('boat').all()),
            ('boats.boatgallery', BoatGallery.objects.select_related('boat').all()),
            ('boats.boatdetails', BoatDetails.objects.select_related('boat').all()),
        ]

    def handle(self, *args, **options):
        parsed_only = options['parsed_only']
        split_mode = options['split']

        self.stdout.write(self.style.SUCCESS('üöÄ –°–æ–∑–¥–∞—é –¥–∞–º–ø –ª–æ–¥–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...'))

        model_querysets = self._get_model_querysets(parsed_only)

        total_count = sum(qs.count() for _, qs in model_querysets)
        parsed_count = ParsedBoat.objects.count()

        if parsed_count == 0:
            self.stdout.write(self.style.WARNING('‚ùå –ù–µ—Ç —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –ª–æ–¥–æ–∫ (ParsedBoat) –≤ –±–∞–∑–µ'))
            return

        self.stdout.write(f'üìã ParsedBoat: {parsed_count}')
        self.stdout.write(f'üì¶ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_count}')

        if split_mode:
            self._dump_split(model_querysets, options['output_dir'], options['max_records'])
        else:
            self._dump_single(model_querysets, options['output'], total_count)

    def _dump_split(self, model_querysets, output_dir, max_records):
        """–î–∞–º–ø –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ –º–æ–¥–µ–ª—è–º —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —á–∞—Å—Ç–∏."""
        out_dir = Path(output_dir)
        out_dir.mkdir(parents=True, exist_ok=True)

        start_time = time.time()
        written_total = 0
        files_created = []

        for idx, (model_label, queryset) in enumerate(model_querysets, 1):
            count = queryset.count()
            if count == 0:
                self.stdout.write(f'  ‚è≠Ô∏è  {model_label}: 0 –∑–∞–ø–∏—Å–µ–π, –ø—Ä–æ–ø—É—Å–∫')
                continue

            short_name = model_label.split('.')[-1]
            need_parts = count > max_records

            self.stdout.write(
                f'  üíæ {model_label} ({count})'
                + (f'  ‚Üí  {(count + max_records - 1) // max_records} —á–∞—Å—Ç–µ–π' if need_parts else '')
            )

            part_num = 1
            file_written = 0
            model_written = 0
            f = None
            first_record = True

            def open_part():
                nonlocal f, first_record, file_written, part_num
                if need_parts:
                    filename = f'{idx:02d}_{short_name}_part{part_num:02d}.json'
                else:
                    filename = f'{idx:02d}_{short_name}.json'
                filepath = out_dir / filename
                f = open(filepath, 'w', encoding='utf-8')
                f.write('[\n')
                first_record = True
                file_written = 0
                return filepath, filename

            def close_part(filepath, filename):
                nonlocal part_num
                f.write('\n]')
                f.close()
                file_size = filepath.stat().st_size / (1024 * 1024)
                self.stdout.write(f'    ‚úÖ {filename}: {file_written} –∑–∞–ø–∏—Å–µ–π, {file_size:.1f} MB')
                files_created.append((filename, file_written, file_size))
                part_num += 1

            filepath, filename = open_part()

            qs = queryset.iterator(chunk_size=BATCH_SIZE)
            batch = []

            for obj in qs:
                batch.append(obj)

                if len(batch) >= BATCH_SIZE:
                    n = self._write_batch(f, batch, first_record)
                    first_record = False
                    file_written += n
                    model_written += n
                    batch = []

                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
                    if need_parts and file_written >= max_records:
                        close_part(filepath, filename)
                        filepath, filename = open_part()

            if batch:
                n = self._write_batch(f, batch, first_record)
                file_written += n
                model_written += n

            close_part(filepath, filename)
            written_total += model_written

        elapsed = time.time() - start_time

        self.stdout.write('')
        self.stdout.write(self.style.SUCCESS(f'‚úÖ Split-–¥–∞–º–ø —Å–æ–∑–¥–∞–Ω –∑–∞ {elapsed:.0f}s'))
        self.stdout.write(f'  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}/')
        self.stdout.write(f'  –§–∞–π–ª–æ–≤: {len(files_created)}')
        self.stdout.write(f'  –ó–∞–ø–∏—Å–µ–π: {written_total}')
        self.stdout.write('')
        self.stdout.write('üí° –ö–æ–ø–∏—Ä—É–π –∏ –≤—ã–ø–æ–ª–Ω—è–π –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ:')
        self.stdout.write('')
        for filename, _, _ in files_created:
            self.stdout.write(f'docker cp {output_dir}/{filename} rent_django-web-1:/app/{filename}')
            self.stdout.write(f'docker-compose exec web python manage.py load_parsed_boats /app/{filename}')
            self.stdout.write(f'docker-compose exec web rm /app/{filename}')
            self.stdout.write('')

    def _dump_single(self, model_querysets, output_path, total_count):
        """–î–∞–º–ø –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º)."""
        try:
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)

            self.stdout.write(f'üíæ –°–æ—Ö—Ä–∞–Ω—è—é –≤ {output_path} (–ø–æ—Ç–æ–∫–æ–≤–∞—è –∑–∞–ø–∏—Å—å)...')

            start_time = time.time()
            written_total = 0
            per_model_counts = []
            first_record = True

            with open(output_file, 'w', encoding='utf-8') as f:
                f.write('[\n')

                for model_label, queryset in model_querysets:
                    model_count = 0
                    qs = queryset.iterator(chunk_size=BATCH_SIZE)
                    batch = []

                    for obj in qs:
                        batch.append(obj)

                        if len(batch) >= BATCH_SIZE:
                            model_count += self._write_batch(f, batch, first_record)
                            first_record = False
                            written_total += len(batch)
                            batch = []

                            if written_total % 10000 == 0:
                                elapsed = time.time() - start_time
                                self.stdout.write(
                                    f'  [{written_total}/{total_count}] ({elapsed:.0f}s)'
                                )

                    if batch:
                        model_count += self._write_batch(f, batch, first_record)
                        first_record = False
                        written_total += len(batch)

                    per_model_counts.append((model_label, model_count))
                    if model_count > 0:
                        self.stdout.write(f'  ‚úÖ {model_label}: {model_count}')

                f.write('\n]')

            elapsed = time.time() - start_time
            file_size = output_file.stat().st_size / (1024 * 1024)

            details_lines = '\n'.join(
                f'  - {label}: {count}'
                for label, count in per_model_counts
                if count > 0
            )

            self.stdout.write(
                self.style.SUCCESS(
                    f'\n‚úÖ –î–∞–º–ø —Å–æ–∑–¥–∞–Ω –∑–∞ {elapsed:.0f}s!\n'
                    f'  –§–∞–π–ª: {output_path}\n'
                    f'  –†–∞–∑–º–µ—Ä: {file_size:.2f} MB\n'
                    f'  –ó–∞–ø–∏—Å–µ–π: {written_total}\n'
                    f'  –ú–æ–¥–µ–ª–∏:\n{details_lines}\n\n'
                    f'üí° –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏:\n'
                    f'   python manage.py load_parsed_boats {output_path}'
                )
            )

        except Exception as e:
            self.stdout.write(self.style.ERROR(f'‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–º–ø–∞: {e}'))
            logger.error(f"Error creating dump: {e}", exc_info=True)

    def _write_batch(self, f, objects, first_record):
        """–°–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç –∏ –ø–∏—à–µ—Ç –±–∞—Ç—á –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ñ–∞–π–ª."""
        serialized = serialize('json', objects, ensure_ascii=False)
        records = json.loads(serialized)

        for record in records:
            if not first_record:
                f.write(',\n')
            else:
                first_record = False
            json.dump(record, f, ensure_ascii=False)

        return len(records)
